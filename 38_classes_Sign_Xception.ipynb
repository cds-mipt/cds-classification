{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import keras\n",
    "import sys\n",
    "\n",
    "# Import architectures\n",
    "from keras.applications import xception\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image as im\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Input, AveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train phase\n",
    "\n",
    "tf.keras.backend.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose GPU\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Path to train and test datasets\n",
    "train_dir = \"/home/linnik/Datasets/Signs/38_Classes/train/\"   \n",
    "test_dir = \"/home/linnik/Datasets/Signs/38_Classes/test/\"\n",
    "\n",
    "\n",
    "# 2) Target width and height of input images, number of classes, number of train and test images, batch size, epochs\n",
    "img_height, img_width = 72, 72\n",
    "n_classes = len(os.listdir(train_dir))\n",
    "nb_train_samples = sum([len(os.listdir(train_dir + folder)) for folder in os.listdir(train_dir)])\n",
    "nb_test_samples = sum([len(os.listdir(test_dir + folder)) for folder in os.listdir(test_dir)])\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "# 3) Name of file where will be saved trained model\n",
    "model_name = \"/home/linnik/Nets/Sign_Xception_72X72x3_38Classes.hdf5\"\n",
    "\n",
    "\n",
    "# 4) Compile parametrs\n",
    "loss_ = 'categorical_crossentropy'\n",
    "optimizer_ = 'adam'\n",
    "metrics_ = ['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1.0 / 255,\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range = 5,\n",
    "    width_shift_range = img_width // 3,\n",
    "    height_shift_range = img_height // 3,\n",
    "    horizontal_flip = False,\n",
    "    vertical_flip = False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 122294 images belonging to 38 classes.\n",
      "Found 16984 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 0,\n",
       " '01': 1,\n",
       " '02': 2,\n",
       " '03': 3,\n",
       " '04': 4,\n",
       " '05': 5,\n",
       " '06': 6,\n",
       " '07': 7,\n",
       " '08': 8,\n",
       " '09': 9,\n",
       " '10': 10,\n",
       " '11': 11,\n",
       " '12': 12,\n",
       " '13': 13,\n",
       " '14': 14,\n",
       " '15': 15,\n",
       " '16': 16,\n",
       " '17': 17,\n",
       " '18': 18,\n",
       " '19': 19,\n",
       " '20': 20,\n",
       " '21': 21,\n",
       " '22': 22,\n",
       " '23': 23,\n",
       " '24': 24,\n",
       " '25': 25,\n",
       " '26': 26,\n",
       " '27': 27,\n",
       " '28': 28,\n",
       " '29': 29,\n",
       " '30': 30,\n",
       " '31': 31,\n",
       " '32': 32,\n",
       " '33': 33,\n",
       " '34': 34,\n",
       " '35': 35,\n",
       " '36': 36,\n",
       " '37': 37}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(72, 72, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check size\n",
    "\n",
    "for x, y in train_generator:\n",
    "    plt.imshow(x[0])\n",
    "    print(y[0])\n",
    "    print(x[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and compile Xception model\n",
    "\n",
    "def build_model_Xception():\n",
    "    base_model = xception.Xception(include_top = True, \n",
    "                                      weights = None,\n",
    "                                      input_tensor = None,\n",
    "                                      input_shape = (img_height, img_width, 3),\n",
    "                                      pooling = None,\n",
    "                                      classes = n_classes)\n",
    "  \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "      \n",
    "    model = Model(inputs = base_model.input, outputs = base_model.output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model_Xception()\n",
    "model.compile(loss = loss_, optimizer = optimizer_, metrics = metrics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 8, verbose = 1, min_delta = 1e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 4, verbose = 1, min_delta = 1e-4)\n",
    "check = ModelCheckpoint(filepath = model_name, monitor = \"val_acc\", save_best_only = True)\n",
    "\n",
    "callbacks_list = [early_stop, reduce_lr, check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "726/955 [=====================>........] - ETA: 53s - loss: 0.8975 - acc: 0.7135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/PIL/Image.py:989: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955/955 [==============================] - 232s 243ms/step - loss: 0.7339 - acc: 0.7660 - val_loss: 0.2225 - val_acc: 0.9399\n",
      "Epoch 2/100\n",
      "955/955 [==============================] - 176s 184ms/step - loss: 0.1479 - acc: 0.9541 - val_loss: 0.1869 - val_acc: 0.9476\n",
      "Epoch 3/100\n",
      "955/955 [==============================] - 176s 184ms/step - loss: 0.1066 - acc: 0.9673 - val_loss: 0.0837 - val_acc: 0.9759\n",
      "Epoch 4/100\n",
      "955/955 [==============================] - 176s 185ms/step - loss: 0.0906 - acc: 0.9723 - val_loss: 0.0770 - val_acc: 0.9770\n",
      "Epoch 5/100\n",
      "955/955 [==============================] - 177s 185ms/step - loss: 0.0779 - acc: 0.9764 - val_loss: 0.0685 - val_acc: 0.9810\n",
      "Epoch 6/100\n",
      "955/955 [==============================] - 177s 185ms/step - loss: 0.0737 - acc: 0.9780 - val_loss: 0.0984 - val_acc: 0.9753\n",
      "Epoch 7/100\n",
      "955/955 [==============================] - 177s 186ms/step - loss: 0.0619 - acc: 0.9811 - val_loss: 0.0745 - val_acc: 0.9795\n",
      "Epoch 8/100\n",
      "955/955 [==============================] - 177s 185ms/step - loss: 0.0602 - acc: 0.9818 - val_loss: 0.0412 - val_acc: 0.9900\n",
      "Epoch 9/100\n",
      "955/955 [==============================] - 176s 185ms/step - loss: 0.0549 - acc: 0.9835 - val_loss: 0.0538 - val_acc: 0.9848\n",
      "Epoch 10/100\n",
      "955/955 [==============================] - 176s 185ms/step - loss: 0.0508 - acc: 0.9844 - val_loss: 0.0782 - val_acc: 0.9790\n",
      "Epoch 11/100\n",
      "955/955 [==============================] - 178s 186ms/step - loss: 0.0468 - acc: 0.9859 - val_loss: 0.0410 - val_acc: 0.9898\n",
      "Epoch 12/100\n",
      "955/955 [==============================] - 177s 185ms/step - loss: 0.0450 - acc: 0.9862 - val_loss: 0.0284 - val_acc: 0.9925\n",
      "Epoch 13/100\n",
      "955/955 [==============================] - 177s 185ms/step - loss: 0.0410 - acc: 0.9874 - val_loss: 0.0279 - val_acc: 0.9929\n",
      "Epoch 14/100\n",
      "955/955 [==============================] - 176s 185ms/step - loss: 0.0419 - acc: 0.9871 - val_loss: 0.0303 - val_acc: 0.9914\n",
      "Epoch 15/100\n",
      "955/955 [==============================] - 177s 185ms/step - loss: 0.0373 - acc: 0.9883 - val_loss: 0.0507 - val_acc: 0.9877\n",
      "Epoch 16/100\n",
      "955/955 [==============================] - 177s 185ms/step - loss: 0.0360 - acc: 0.9886 - val_loss: 0.0361 - val_acc: 0.9896\n",
      "Epoch 17/100\n",
      "955/955 [==============================] - 175s 184ms/step - loss: 0.0355 - acc: 0.9892 - val_loss: 0.0456 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 18/100\n",
      "955/955 [==============================] - 176s 185ms/step - loss: 0.0201 - acc: 0.9939 - val_loss: 0.0153 - val_acc: 0.9961\n",
      "Epoch 19/100\n",
      "955/955 [==============================] - 176s 184ms/step - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0173 - val_acc: 0.9962\n",
      "Epoch 20/100\n",
      "955/955 [==============================] - 176s 184ms/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0147 - val_acc: 0.9961\n",
      "Epoch 21/100\n",
      "955/955 [==============================] - 175s 183ms/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.0161 - val_acc: 0.9960\n",
      "Epoch 23/100\n",
      "955/955 [==============================] - 176s 184ms/step - loss: 0.0128 - acc: 0.9959 - val_loss: 0.0148 - val_acc: 0.9968\n",
      "Epoch 24/100\n",
      "955/955 [==============================] - 176s 184ms/step - loss: 0.0125 - acc: 0.9959 - val_loss: 0.0156 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 25/100\n",
      "474/955 [=============>................] - ETA: 1:24 - loss: 0.0111 - acc: 0.9963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train model\n",
    "\n",
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = epochs,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = nb_test_samples // batch_size,\n",
    "    callbacks = callbacks_list,\n",
    "    steps_per_epoch = nb_train_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test phase\n",
    "\n",
    "tf.keras.backend.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "\n",
    "loaded_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16984 images belonging to 38 classes.\n",
      "Average time to pridict one photo using generator is 0.0062612296835296965\n"
     ]
    }
   ],
   "source": [
    "# Speed test using generator\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = 1,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "nb_samples = len(test_generator.filenames)\n",
    "\n",
    "start_time = time.time()\n",
    "predict = loaded_model.predict_generator(test_generator, steps = nb_samples)\n",
    "print(\"Average time to pridict one photo using generator is\", (time.time() - start_time)/nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision_Recall_metrics(test_dir, model):\n",
    "    n_classes = len(os.listdir(test_dir))\n",
    "    \n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    times = []\n",
    "\n",
    "    TP = [0 for i in range(n_classes)]\n",
    "    FN = [0 for i in range(n_classes)]\n",
    "    FP = [0 for i in range(n_classes)]\n",
    "    precision = [0 for i in range(n_classes)]\n",
    "    recall = [0 for i in range(n_classes)]\n",
    "\n",
    "    for folder in os.listdir(test_dir):\n",
    "        for img in os.listdir(test_dir + \"/\" + folder):\n",
    "            imag = im.load_img(test_dir + \"/\" + folder + \"/\" + img, target_size = (img_height, img_width))\n",
    "\n",
    "            photo_ar = im.img_to_array(imag)\n",
    "            photo_ar = np.expand_dims(photo_ar, axis = 0)\n",
    "            photo_ar /= 255\n",
    "\n",
    "            start_time = time.time()\n",
    "            ans = np.argmax(model.predict(photo_ar))\n",
    "            times.append(time.time() - start_time)\n",
    "\n",
    "            if ans == int(folder):\n",
    "                right += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "\n",
    "\n",
    "            if ans == int(folder):\n",
    "                TP[ans] += 1\n",
    "            if ans != int(folder):\n",
    "                FN[ans] += 1\n",
    "                FP[int(folder)] += 1\n",
    "\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        try:\n",
    "            precision[i] = TP[i]/(TP[i] + FP[i])\n",
    "        except:\n",
    "            precision[i] = 0\n",
    "\n",
    "        try:\n",
    "            recall[i] = TP[i]/(TP[i] + FN[i])\n",
    "        except:\n",
    "            recall[i] = 0\n",
    "    precision = np.array(precision)\n",
    "    recall = np.array(recall)\n",
    "    \n",
    "    accuracy = right/(right + wrong)\n",
    "    avr_time = np.array(times).mean()\n",
    "    \n",
    "    return accuracy, avr_time, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is 0.996349505416863\n",
      "Average time to predict one photo without generator is 0.006422488688299581 seconds\n",
      "\n",
      "Precision: [0.9978903  0.99298246 0.99707174 1.         0.99671053 0.99404762\n",
      " 0.99561404 1.         0.99056604 0.9989882  0.99577822 0.993\n",
      " 1.         0.99590164 1.         0.98198198 0.99734748 0.99516908\n",
      " 1.         0.99426934 0.99758454 0.99452055 0.99672131 1.\n",
      " 1.         0.99280576 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.96376812\n",
      " 1.         0.99264706]\n",
      "Recall: [1.         0.99647887 0.99416058 0.99173554 0.99019608 0.98816568\n",
      " 0.99126638 0.99378882 0.99369085 0.9973064  0.995218   0.99899396\n",
      " 1.         1.         0.9921875  1.         0.99470899 1.\n",
      " 0.99776286 0.99426934 1.         0.98910082 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.99570815 1.         1.\n",
      " 0.98550725 0.96428571]\n",
      "\n",
      "Precision max, min, mean: 1.0 0.9637681159420289 0.9961938415364235\n",
      "Recall max, min, mean: 1.0 0.9642857142857143 0.9959087314778969\n",
      "CPU times: user 2min 4s, sys: 5.64 s, total: 2min 10s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "accuracy, avr_time, precision, recall = Precision_Recall_metrics(test_dir, loaded_model)\n",
    "            \n",
    "\n",
    "print(\"Accuracy on test set is\", accuracy)\n",
    "print(\"Average time to predict one photo without generator is\", avr_time, \"seconds\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Precision max, min, mean:\", precision.max(), precision.min(), precision.mean())\n",
    "print(\"Recall max, min, mean:\", recall.max(), recall.min(), recall.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(range(n_classes), recall, label = \"Recall\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.title(\"ResnetM\")\n",
    "\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAF1CAYAAADiNYyJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAaiElEQVR4nO3df7RdZX3n8c+XBAlFlErSDiVAcAjYSNrAulCUOuPS2gG10OmINaNVXLRMVdQZ7FjszMIOxVn94Vh/LFoHlzXWUX4MbZ0MjUWZotVZxUnECAKCkQZzIwqiaFAQUp/5457QwyU3OeGecHN9Xq+17uKcffbZ5zkPG+47O/ucXa21AABAb/ab6wEAAMBcEMIAAHRJCAMA0CUhDABAl4QwAABdEsIAAHRJCAMA0CUhDDAGVbW5qh6oqvur6utVtaaqnjyGbd5dVQcNLfv1qvrkiM9fU1UX72SbD1XV4mnLP19VraqWzWbMAPOJEAYYn19qrT05yaokJyR5yxi2uSDJG8ewnWH/kGT1jjtVtTLJj435NQD2eUIYYMxaa19Pck2mgjhVdUBVvb2qvlpV36iq91bVgYPHFlfV1VV1X1V9q6o+XVXD/2/+oyS/VVWH7Oy1quoZVfWJwXNvq6qXDpafm+TlSd48OEr9v4ee9qEkrxy6/6okfz6u9w8wXwhhgDGrqqVJTk+yabDo95Mcm6kwPibJ4UkuHDz2piSTSZYk+ckkv5OkDW1uQ5JPJvmtnbzOQUk+keQjSX4iycuS/ElVrWitXZrkw0n+sLX25NbaLw099fokT6mqn66qBYPn/Y9Zvm2AeUcIA4zPR6tqW5ItSe5O8taqqiTnJvkPrbVvtda2JfmvmYrPJHk4yWFJjmqtPdxa+3RrrU3b7oVJXl9VS6Ytf3GSza21D7TWtrfWPp/kL5KcNcJYdxwVfkGSW5Ns3eN3CzDPCWGA8fnl1trBSZ6b5BlJFmfqSO+PJfnc4PSH+5L8zWB5MnXqw6YkH6+qO6rqgukbba19McnVSaY/dlSSn9ux3cG2X57kn40w1g8l+bdJzo7TIoBOCWGAMWutfSrJmiRvT/LNJA8keWZr7ZDBz1MHH6pLa21ba+1NrbWnJzkjyflV9fydbPatSX4jU6dV7LAlyaeGtnvI4DSI1+wYyi7GeGemPjT3wiR/Oas3DDBPCWGAveOdmTrtYGWS9yX546r6iSSpqsOr6l8Nbr+4qo4ZnELxnST/mOSH0zfWWtuU5IokbxhafHWSY6vq16pq/8HPSVX104PHv5Hk6bsY4zlJntda+96s3inAPCWEAfaC1to9mTrl4MIkv52p0x+ur6rvJrk2yXGDVZcP7t+f5O+T/Elr7boZNntRkke+U3hwvvEvZup8468l+XqSP0hywGCV9ydZMTht4qM7GeNXWmsbZvM+AeazeuxnMgAA4EefI8IAAHRJCAMA0CUhDABAl4QwAABdEsIAAHRp4Vy98OLFi9uyZcvm6uUBAOjE5z73uW+21qZfpn7uQnjZsmXZsMHXVwIAsHdV1Z07W+7UCAAAuiSEAQDokhAGAKBLc3aOMAAAj/bwww9ncnIyDz744FwPZV5atGhRli5dmv3333+k9YUwAMA+YnJyMgcffHCWLVuWqprr4cwrrbXce++9mZyczNFHHz3Sc5waAQCwj3jwwQdz6KGHiuDHoapy6KGH7tHRdCEMALAPEcGP357OnRAGAOARCxYsyKpVq3L88cfnrLPOyve///1Zb3PDhg15wxveMOPjX/va1/KSl7xk1q+zp5wjDACwj1p2wV+PdXubf/9Fu13nwAMPzMaNG5MkL3/5y/Pe9743559//iOPt9bSWst++41+PHViYiITExMzPv5TP/VTueqqq0be3rg4IgwAwE495znPyaZNm7J58+Ycd9xxeeUrX5njjz8+W7Zsycc//vE861nPyoknnpizzjor999/f5Jk/fr1efazn52f/dmfzcknn5xt27blk5/8ZF784hcnST71qU9l1apVWbVqVU444YRs27YtmzdvzvHHH59k6jzpV7/61Vm5cmVOOOGEXHfddUmSNWvW5Fd+5Vdy2mmnZfny5Xnzm9886/e32xCuqj+rqrur6oszPF5V9e6q2lRVN1bVibMeFQAAc2r79u352Mc+lpUrVyZJvvzlL+e1r31tbr755hx00EG5+OKLc+211+aGG27IxMRE3vGOd+Shhx7Kr/7qr+Zd73pXvvCFL+Taa6/NgQce+Kjtvv3tb88ll1ySjRs35tOf/vRjHr/kkktSVbnpppty2WWX5VWvetUjH4DbuHFjrrjiitx000254oorsmXLllm9x1GOCK9JctouHj89yfLBz7lJ/nRWIwIAYM488MADWbVqVSYmJnLkkUfmnHPOSZIcddRROeWUU5Ik119/fW655ZaceuqpWbVqVT74wQ/mzjvvzG233ZbDDjssJ510UpLkKU95ShYufPSZuKeeemrOP//8vPvd78599933mMc/85nP5BWveEWS5BnPeEaOOuqo3H777UmS5z//+XnqU5+aRYsWZcWKFbnzzjtn9V53e45wa+3vqmrZLlY5M8mft9Zakuur6pCqOqy1dtesRgYAwBNu+BzhYQcddNAjt1trecELXpDLLrvsUevcdNNNu93+BRdckBe96EVZt25dTj311FxzzTVZtGjRSGM74IADHrm9YMGCbN++faTnzWQcH5Y7PMnwcenJwbLHhHBVnZupo8Y58sgjx/DSfXo8J86PcnL8fDHX73+uX38c5vo9zPXrz7Xe3/84zHYO5/rfwVyPfxzvf0+3MdvnT9/Gj+rz33fGYXl48r493vaeunEXr/HD9tjHt9713UfdP+WUU/K6170umzZtyjHHHJPvfe972bp1a4477rjcddddWb9+fU466aRs27btMac+fOUrX8nKlSuzcuXKrF+/Pl/60peyatWqRx5/znOekw9/+MN53vOel9tvvz1f/epXc9xxx+WGG24Ywzt/tCf0WyNaa5cmuTRJJiYm2hP52sNm+x/vE/364x7DXL8+c78PztZ834fm+/jHYa73Qf8OYH5bsmRJ1qxZk9WrV+cHP/hBkuTiiy/OsccemyuuuCKvf/3r88ADD+TAAw/Mtdde+6jnvvOd78x1112X/fbbL8985jNz+umn5667/un46Wtf+9q85jWvycqVK7Nw4cKsWbPmUUeCx2kcIbw1yRFD95cOlv3ImutfIHNtrv8UjTmca3M9/3P9+vvKGOZS7++fJ87a80595PbPLD3kCXnN62+bfMyyw484Ml/84j99b8KNk/dl8bEn5v1/9YlHrXfj5H054LDlufSqv3lk2R33bc/TjlmVq6++Oknynve85zHbX7Zs2SPbX7RoUT7wgQ88Zp2zzz47Z5999iP3d2xvNsYRwmuTnFdVlyf5uSTfcX4w+zK/wACAZIQQrqrLkjw3yeKqmkzy1iT7J0lr7b1J1iV5YZJNSb6f5NV7a7AAADAuo3xrxOrdPN6SvG5sIwIAgCeASywD847TW4AfVS1Tly+uqrkeyrw0dXx2dC6xDACwj7jzvoez/fvf3eOgYyqC77333pG/kzhxRBgAYJ/xns9+O69PctQh30zl0UeFb9124M6f9Dh849sP7PFzhl9/ts/fWxYtWpSlS5eOvL4QBgDYR3z3Bz/M2/7u3p0+Ns5TvE6f5Slms33+vsKpEQAAdMkRYQCAecaHhsfDEWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgSyOFcFWdVlW3VdWmqrpgJ48fWVXXVdXnq+rGqnrh+IcKAADjs9sQrqoFSS5JcnqSFUlWV9WKaav95yRXttZOSPKyJH8y7oECAMA4jXJE+OQkm1prd7TWHkpyeZIzp63TkjxlcPupSb42viECAMD4jRLChyfZMnR/crBs2O8meUVVTSZZl+T1O9tQVZ1bVRuqasM999zzOIYLAADjMa4Py61Osqa1tjTJC5N8qKoes+3W2qWttYnW2sSSJUvG9NIAALDnRgnhrUmOGLq/dLBs2DlJrkyS1trfJ1mUZPE4BggAAHvDKCG8Psnyqjq6qp6UqQ/DrZ22zleTPD9JquqnMxXCzn0AAGCftdsQbq1tT3JekmuS3Jqpb4e4uaouqqozBqu9KclvVNUXklyW5OzWWttbgwYAgNlaOMpKrbV1mfoQ3PCyC4du35Lk1PEODQAA9h5XlgMAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEtCGACALglhAAC6JIQBAOiSEAYAoEsjhXBVnVZVt1XVpqq6YIZ1XlpVt1TVzVX1kfEOEwAAxmvh7laoqgVJLknygiSTSdZX1drW2i1D6yxP8pYkp7bWvl1VP7G3BgwAAOMwyhHhk5Nsaq3d0Vp7KMnlSc6cts5vJLmktfbtJGmt3T3eYQIAwHiNEsKHJ9kydH9ysGzYsUmOrar/W1XXV9VpO9tQVZ1bVRuqasM999zz+EYMAABjMK4Pyy1MsjzJc5OsTvK+qjpk+kqttUtbaxOttYklS5aM6aUBAGDPjRLCW5McMXR/6WDZsMkka1trD7fW/iHJ7ZkKYwAA2CeNEsLrkyyvqqOr6klJXpZk7bR1Ppqpo8GpqsWZOlXijjGOEwAAxmq3Idxa257kvCTXJLk1yZWttZur6qKqOmOw2jVJ7q2qW5Jcl+Q/ttbu3VuDBgCA2drt16clSWttXZJ105ZdOHS7JTl/8AMAAPs8V5YDAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLQhgAgC4JYQAAuiSEAQDokhAGAKBLI4VwVZ1WVbdV1aaqumAX6/2bqmpVNTG+IQIAwPjtNoSrakGSS5KcnmRFktVVtWIn6x2c5I1JPjvuQQIAwLiNckT45CSbWmt3tNYeSnJ5kjN3st7vJfmDJA+OcXwAALBXjBLChyfZMnR/crDsEVV1YpIjWmt/PcaxAQDAXjPrD8tV1X5J3pHkTSOse25VbaiqDffcc89sXxoAAB63UUJ4a5Ijhu4vHSzb4eAkxyf5ZFVtTnJKkrU7+8Bca+3S1tpEa21iyZIlj3/UAAAwS6OE8Poky6vq6Kp6UpKXJVm748HW2ndaa4tba8taa8uSXJ/kjNbahr0yYgAAGIPdhnBrbXuS85Jck+TWJFe21m6uqouq6oy9PUAAANgbFo6yUmttXZJ105ZdOMO6z539sAAAYO9yZTkAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALo0UghX1WlVdVtVbaqqC3by+PlVdUtV3VhV/6eqjhr/UAEAYHx2G8JVtSDJJUlOT7IiyeqqWjFttc8nmWit/UySq5L84bgHCgAA4zTKEeGTk2xqrd3RWnsoyeVJzhxeobV2XWvt+4O71ydZOt5hAgDAeI0Swocn2TJ0f3KwbCbnJPnYbAYFAAB728JxbqyqXpFkIsm/nOHxc5OcmyRHHnnkOF8aAAD2yChHhLcmOWLo/tLBskepql9I8p+SnNFa+8HONtRau7S1NtFam1iyZMnjGS8AAIzFKCG8Psnyqjq6qp6U5GVJ1g6vUFUnJPnvmYrgu8c/TAAAGK/dhnBrbXuS85Jck+TWJFe21m6uqouq6ozBan+U5MlJ/mdVbayqtTNsDgAA9gkjnSPcWluXZN20ZRcO3f6FMY8LAAD2KleWAwCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgS0IYAIAuCWEAALokhAEA6JIQBgCgSyOFcFWdVlW3VdWmqrpgJ48fUFVXDB7/bFUtG/dAAQBgnHYbwlW1IMklSU5PsiLJ6qpaMW21c5J8u7V2TJI/TvIH4x4oAACM0yhHhE9Osqm1dkdr7aEklyc5c9o6Zyb54OD2VUmeX1U1vmECAMB4jRLChyfZMnR/crBsp+u01rYn+U6SQ8cxQAAA2BuqtbbrFapekuS01tqvD+7/WpKfa62dN7TOFwfrTA7uf2WwzjenbevcJOcO7h6X5LZxvZExWZzkm7tdi5mYv9kzh7NnDmfH/M2eOZwd8zd75vCxjmqtLZm+cOEIT9ya5Iih+0sHy3a2zmRVLUzy1CT3Tt9Qa+3SJJeOOuInWlVtaK1NzPU45ivzN3vmcPbM4eyYv9kzh7Nj/mbPHI5ulFMj1idZXlVHV9WTkrwsydpp66xN8qrB7Zck+du2u0PNAAAwh3Z7RLi1tr2qzktyTZIFSf6stXZzVV2UZENrbW2S9yf5UFVtSvKtTMUyAADss0Y5NSKttXVJ1k1bduHQ7QeTnDXeoc2Jffa0jXnC/M2eOZw9czg75m/2zOHsmL/ZM4cj2u2H5QAA4EeRSywDANAlIZzdX0Ka3auqzVV1U1VtrKoNcz2e+aCq/qyq7h58/eCOZU+rqk9U1ZcH//zxuRzjvmyG+fvdqto62A83VtUL53KM+7KqOqKqrquqW6rq5qp642C5fXBEu5hD++GIqmpRVf2/qvrCYA7/y2D50VX12cHv5SsGH9Znml3M35qq+oehfXDVXI91X9X9qRGDS0jfnuQFmbpYyPokq1trt8zpwOaZqtqcZGL6d0czs6r6F0nuT/LnrbXjB8v+MMm3Wmu/P/hD2Y+31n57Lse5r5ph/n43yf2ttbfP5djmg6o6LMlhrbUbqurgJJ9L8stJzo59cCS7mMOXxn44ksFVaA9qrd1fVfsn+UySNyY5P8lfttYur6r3JvlCa+1P53Ks+6JdzN9vJrm6tXbVnA5wHnBEeLRLSMPYtdb+LlPfsjJs+HLlH8zUL1V2Yob5Y0SttbtaazcMbm9LcmumrhJqHxzRLuaQEbUp9w/u7j/4aUmel2RHxNkPZ7CL+WNEQni0S0izey3Jx6vqc4MrCPL4/GRr7a7B7a8n+cm5HMw8dV5V3Tg4dcJf64+gqpYlOSHJZ2MffFymzWFiPxxZVS2oqo1J7k7yiSRfSXJfa237YBW/l3dh+vy11nbsg28b7IN/XFUHzOEQ92lCmHH5+dbaiUlOT/K6wV9bMwuDi9L4k/2e+dMk/zzJqiR3JflvczucfV9VPTnJXyT596217w4/Zh8czU7m0H64B1pr/9haW5WpK9eenOQZczykeWX6/FXV8Unekql5PCnJ05I4vWkGQni0S0izG621rYN/3p3krzL1PzP23DcG5x3uOP/w7jkez7zSWvvG4JfCD5O8L/bDXRqcU/gXST7cWvvLwWL74B7Y2RzaDx+f1tp9Sa5L8qwkh1TVjmsd+L08gqH5O21w2k5rrf0gyQdiH5yREB7tEtLsQlUdNPigSKrqoCS/mOSLu34WMxi+XPmrkvyvORzLvLMj4Ab+deyHMxp8yOb9SW5trb1j6CH74IhmmkP74eiqaklVHTK4fWCmPrh+a6aC7iWD1eyHM5hh/r409IfZytT51fbBGXT/rRFJMvhqm3fmny4h/bY5HtK8UlVPz9RR4GTqaoUfMYe7V1WXJXluksVJvpHkrUk+muTKJEcmuTPJS1trPhC2EzPM33Mz9dfRLcnmJP9u6HxXhlTVzyf5dJKbkvxwsPh3MnWOq31wBLuYw9WxH46kqn4mUx+GW5Cpg3NXttYuGvxeuTxTf63/+SSvGBzdZMgu5u9vkyxJUkk2JvnNoQ/VMUQIAwDQJadGAADQJSEMAECXhDAAAF0SwgAAdEkIAwDQJSEMAECXhDAAAF0SwgAAdOn/A7iCBP3x0wC5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(range(n_classes), precision, label = \"Precision\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.title(\"ResNetM\")\n",
    "\n",
    "\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-d22d3fe33d9a>:3: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.remove_training_nodes`\n",
      "WARNING:tensorflow:From <ipython-input-31-d22d3fe33d9a>:4: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/linnik/.conda/envs/linnik/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 146 variables.\n",
      "INFO:tensorflow:Converted 146 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "def freeze_graph(graph, session, output, save_pb_dir = '.', save_pb_name = 'frozen_model.pb', save_pb_as_text=False):\n",
    "    with graph.as_default():\n",
    "        graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
    "        graphdef_frozen = tf.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
    "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
    "        return graphdef_frozen\n",
    "\n",
    "session = tf.keras.backend.get_session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "\n",
    "\n",
    "input_names = [t.op.name for t in model.inputs]\n",
    "output_names = [t.op.name for t in model.outputs]\n",
    "\n",
    "frozen_graph = freeze_graph(session.graph, session, [out.op.name for out in model.outputs], \n",
    "                            save_pb_dir = '.', save_pb_name = 'frozen_model_ct2_Sign_ResNetM_72X72x3_33.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_1'] ['fc5/Softmax']\n"
     ]
    }
   ],
   "source": [
    "# Prints input and output nodes names, take notes of them\n",
    "\n",
    "print(input_names, output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for photo in os.listdir(test_dir + \"34\"):\n",
    "    imag = im.load_img(test_dir + \"34/\" + photo, target_size = (img_height, img_width))\n",
    "\n",
    "    photo_ar = im.img_to_array(imag)\n",
    "    photo_ar = np.expand_dims(photo_ar, axis = 0)\n",
    "    photo_ar /= 255\n",
    "    \n",
    "    pred = np.argmax(loaded_model.predict(photo_ar))    \n",
    "    if pred != 34:\n",
    "        shutil.move(test_dir + \"34/\" + photo, train_dir + \"34/\" + photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune NKBVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_dir = \"/home/linnik/Datasets/Signs/nkbvs_ts_crops_RGB/\"\n",
    "temp_dir = \"/home/linnik/Datasets/Signs/temp/\"\n",
    "\n",
    "for img in os.listdir(photos_dir):\n",
    "    imag = im.load_img(photos_dir + img, target_size = (img_height, img_width))\n",
    "\n",
    "    photo_ar = im.img_to_array(imag)\n",
    "    photo_ar = np.expand_dims(photo_ar, axis = 0)\n",
    "    photo_ar /= 255\n",
    "\n",
    "    pred = np.argmax(loaded_model.predict(photo_ar))\n",
    "    \n",
    "    os.makedirs(temp_dir + str(pred), exist_ok = True)\n",
    "    shutil.copy(photos_dir + img, temp_dir + str(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
